generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id        String    @id @default(uuid())
  email     String    @unique
  password  String
  projects  Project[]
  createdAt DateTime  @default(now())
  updatedAt DateTime  @updatedAt
}

model Project {
  id          String   @id @default(uuid())
  name        String
  description String?
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  prompts     Prompt[]
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
}

model Prompt {
  id        String          @id @default(uuid())
  name      String
  projectId String
  project   Project         @relation(fields: [projectId], references: [id])
  versions  PromptVersion[]
  batchRuns BatchRun[]
  createdAt DateTime        @default(now())
  updatedAt DateTime        @updatedAt
}

model PromptVersion {
  id            String   @id @default(uuid())
  promptId      String
  prompt        Prompt   @relation(fields: [promptId], references: [id])
  versionNumber Int
  template      String
  model         String   @default("llama-3.3-70b-versatile")
  commitMessage String?
  createdAt     DateTime @default(now())
}

model BatchRun {
  id        String        @id @default(uuid())
  promptId  String
  prompt    Prompt        @relation(fields: [promptId], references: [id])
  createdAt DateTime      @default(now())
  results   BatchResult[]
}

model BatchResult {
  id         String   @id @default(uuid())
  batchRunId String
  batchRun   BatchRun @relation(fields: [batchRunId], references: [id])
  inputs     Json
  output     String
  status     String   // e.g., "success", "error"
  
  // New metrics for evaluation requirements
  latencyMs    Int?
  tokenCount   Int?
  cost         Float?
  qualityScore Float? // For automated metric (0.0 to 1.0)
}